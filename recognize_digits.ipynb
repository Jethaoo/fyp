{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a3d52-fbe8-42e1-b9e4-c6023aca63dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and crop (ROI)\n",
    "img = cv2.imread('digit.jpg')\n",
    "\n",
    "# Adjust ROI values as needed (x, y, w, h)\n",
    "x, y, w, h = 757, 378, 780, 700\n",
    "roi = img[y:y+h, x:x+w]\n",
    "\n",
    "# 2. Grayscale\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 3. Noise Reduction\n",
    "blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "# 4. Thresholding (Otsu)\n",
    "_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# 5. Edge Detection\n",
    "edges = cv2.Canny(thresh, 50, 150)\n",
    "\n",
    "# 6. Contour Detection\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a copy for drawing\n",
    "contour_img = roi.copy()\n",
    "\n",
    "# Filter and draw contours\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 50:  # filter small noise, adjust threshold as needed\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(c)\n",
    "        # Draw bounding boxes\n",
    "        cv2.rectangle(contour_img, (x_c, y_c), (x_c + w_c, y_c + h_c), (0, 0, 255), 2)\n",
    "        # Optional: mark center\n",
    "        cx = x_c + w_c//2\n",
    "        cy = y_c + h_c//2\n",
    "        cv2.circle(contour_img, (cx, cy), 3, (0, 255, 0), -1)\n",
    "\n",
    "# --- Display results ---\n",
    "cv2.imshow('ROI', roi)\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.imshow('Contours', contour_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06ee6b4-94f5-48ba-85e6-f7488c3c9b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   ------- --------------------------------  3/16 [termcolor]\n",
      "   ------------ ---------------------------  5/16 [optree]\n",
      "   ------------ ---------------------------  5/16 [optree]\n",
      "   --------------- ------------------------  6/16 [opt-einsum]\n",
      "   --------------- ------------------------  6/16 [opt-einsum]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   ---------------------- -----------------  9/16 [google-pasta]\n",
      "   ------------------------- -------------- 10/16 [gast]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ---------------------------------------- 16/16 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0fdda3-88fc-4981-9269-7d25dafe22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 18ms/step - accuracy: 0.8977 - loss: 0.3325 - val_accuracy: 0.9763 - val_loss: 0.0815\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.9823 - loss: 0.0567 - val_accuracy: 0.9877 - val_loss: 0.0432\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9889 - loss: 0.0348 - val_accuracy: 0.9882 - val_loss: 0.0439\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.0473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1,28,28,1).astype('float32')/255.0\n",
    "\n",
    "# Build a simple CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(x_train,y_train,epochs=3,validation_split=0.1)\n",
    "model.evaluate(x_test,y_test)\n",
    "model.save('digit_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce79321-a49a-497e-b0aa-79517cae66ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'digit_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdigit_cnn.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m detected_digits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m digit_images:  \u001b[38;5;66;03m# digit_images is the list you built earlier\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# --- Preprocessing ---\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Resize to 28x28\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     d_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(d, (\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Invert colors if necessary (white digit on black background)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Check visually: if your digits are already white on black, skip this\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'digit_images' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load your saved CNN model (trained on 28x28 digits)\n",
    "model = load_model('digit_cnn.h5')\n",
    "\n",
    "detected_digits = []\n",
    "\n",
    "for d in digit_images:  # digit_images is the list you built earlier\n",
    "    # --- Preprocessing ---\n",
    "    # Resize to 28x28\n",
    "    d_resized = cv2.resize(d, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Invert colors if necessary (white digit on black background)\n",
    "    # Check visually: if your digits are already white on black, skip this\n",
    "    d_resized = 255 - d_resized\n",
    "\n",
    "    # Normalize to 0-1\n",
    "    d_norm = d_resized.astype('float32') / 255.0\n",
    "\n",
    "    # Reshape to (1,28,28,1) for CNN\n",
    "    d_input = d_norm.reshape(1, 28, 28, 1)\n",
    "\n",
    "    # --- Prediction ---\n",
    "    pred = model.predict(d_input, verbose=0)  # probabilities\n",
    "    label = int(np.argmax(pred))              # highest-probability class\n",
    "\n",
    "    detected_digits.append(label)\n",
    "\n",
    "print(\"Predicted digits (unsorted):\", detected_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4675e84-f4b4-42a0-91b8-9f5290a2daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"DIGIT\",\n",
    "    image_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    label_mode='int'  # gives you integer labels 0–9\n",
    ")\n",
    "\n",
    "# Optional: normalize pixels from [0,255] to [0,1]\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925a8b0d-52ce-4335-8ab3-6d52eebb33aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 2.3157\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4000 - loss: 2.2521\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6000 - loss: 2.1950\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6000 - loss: 2.1359\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7000 - loss: 2.0723\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8000 - loss: 2.0009\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8000 - loss: 1.9187\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8000 - loss: 1.8251\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9000 - loss: 1.7213\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9000 - loss: 1.6085\n",
      "✅ Model saved as digit_cnn.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, epochs=10)\n",
    "\n",
    "# Save the model in new Keras format\n",
    "model.save('digit_cnn.keras')\n",
    "print(\"✅ Model saved as digit_cnn.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d643bd7-10be-494e-83eb-6d5ba924f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "Predicted digit: 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('digit_cnn.keras')\n",
    "\n",
    "img = cv2.imread('test3.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = 255 - img  # invert if needed\n",
    "img = img.astype('float32')/255.0\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "pred = model.predict(img)\n",
    "print(\"Predicted digit:\", np.argmax(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "399980ae-3ded-400f-8bc4-d082dc84ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- Load trained model ---\n",
    "model = load_model('digit_cnn.keras')\n",
    "\n",
    "# --- Load image and preprocess (same as before) ---\n",
    "img = cv2.imread('digit.jpg')\n",
    "x, y, w, h = 757, 378, 780, 700  # your ROI\n",
    "roi = img[y:y+h, x:x+w]\n",
    "\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# --- Find contours ---\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# --- Sort contours left to right ---\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# --- Copy image for drawing ---\n",
    "annotated = roi.copy()\n",
    "\n",
    "# --- Loop through contours ---\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 50:  # filter small noise\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(c)\n",
    "\n",
    "        # Crop digit patch\n",
    "        digit_patch = thresh[y_c:y_c+h_c, x_c:x_c+w_c]\n",
    "\n",
    "        # Preprocess for model\n",
    "        d_resized = cv2.resize(digit_patch, (28,28))\n",
    "        d_resized = 255 - d_resized  # invert if needed\n",
    "        d_norm = d_resized.astype('float32')/255.0\n",
    "        d_input = d_norm.reshape(1,28,28,1)\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(d_input, verbose=0)\n",
    "        label = int(np.argmax(pred))\n",
    "\n",
    "        # Draw rectangle on annotated image\n",
    "        cv2.rectangle(annotated, (x_c, y_c), (x_c+w_c, y_c+h_c), (0,255,0), 2)\n",
    "\n",
    "        # Put label text\n",
    "        cv2.putText(annotated, str(label), (x_c, y_c-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "# --- Show final annotated image ---\n",
    "cv2.imshow('Detected Digits', annotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aee3714-a423-4122-9537-aa715a937616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected digits: [7, 7, 5, 4, 0, 6, 0, 6, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- Load trained CNN model ---\n",
    "model = load_model('digit_cnn.keras')\n",
    "\n",
    "# --- Load and crop ROI ---\n",
    "img = cv2.imread('test3.png')\n",
    "#x, y, w, h = 757, 378, 780, 700  # adjust to your ROI\n",
    "roi = img\n",
    "\n",
    "# --- Preprocess ---\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# ✅ Morphological closing to merge segments\n",
    "kernel = np.ones((7,7), np.uint8)# tune size if needed\n",
    "closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# --- Find contours on closed image ---\n",
    "contours, hierarchy = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours left-to-right\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "# Copy for drawing\n",
    "annotated = roi.copy()\n",
    "\n",
    "detected_digits = []\n",
    "\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 100:  # filter tiny noise\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(c)\n",
    "\n",
    "        # Crop the digit region\n",
    "        digit_patch = thresh[y_c:y_c+h_c, x_c:x_c+w_c]\n",
    "\n",
    "        # Preprocess for model\n",
    "        d_resized = cv2.resize(digit_patch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "        d_resized = 255 - d_resized  # invert if needed\n",
    "        d_norm = d_resized.astype('float32') / 255.0\n",
    "        d_input = d_norm.reshape(1, 28, 28, 1)\n",
    "\n",
    "        # Predict with CNN\n",
    "        pred = model.predict(d_input, verbose=0)\n",
    "        label = int(np.argmax(pred))\n",
    "        detected_digits.append(label)\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(annotated, (x_c, y_c), (x_c+w_c, y_c+h_c), (0,255,0), 2)\n",
    "        cv2.putText(annotated, str(label), (x_c, y_c-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "# Show results\n",
    "cv2.imshow('Closed', closed)         # see merged mask\n",
    "cv2.imshow('Detected Digits', annotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Detected digits:\", detected_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e143419-49ca-4642-a9a3-28f31736aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected digits: [6, 6, 4, 7, 2, 0, 7, 7, 9, 2, 7, 6, 7, 2, 5, 7, 6, 7, 0, 6, 0, 8, 0, 6, 7, 0, 5, 6, 6, 9, 0, 6, 0, 6, 6, 0, 6, 4, 7, 6, 6, 4, 2, 7, 4, 7, 0, 6, 6, 0, 7, 0, 6]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained CNN model\n",
    "model = load_model('digit_cnn.keras')\n",
    "\n",
    "# Load full image (no cropping)\n",
    "img = cv2.imread('digit.jpg')\n",
    "roi = img  # directly use the whole image\n",
    "\n",
    "# Preprocessing\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Morphological closing to merge segments\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "annotated = roi.copy()\n",
    "detected_digits = []\n",
    "\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 100:  # filter tiny noise\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(c)\n",
    "        digit_patch = thresh[y_c:y_c+h_c, x_c:x_c+w_c]\n",
    "\n",
    "        # Preprocess for model\n",
    "        d_resized = cv2.resize(digit_patch, (28,28))\n",
    "        d_resized = 255 - d_resized\n",
    "        d_norm = d_resized.astype('float32') / 255.0\n",
    "        d_input = d_norm.reshape(1, 28, 28, 1)\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(d_input, verbose=0)\n",
    "        label = int(np.argmax(pred))\n",
    "        detected_digits.append(label)\n",
    "\n",
    "        # Draw results\n",
    "        cv2.rectangle(annotated, (x_c, y_c), (x_c+w_c, y_c+h_c), (0,255,0), 2)\n",
    "        cv2.putText(annotated, str(label), (x_c, y_c-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('Closed', closed)\n",
    "cv2.imshow('Detected Digits', annotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Detected digits:\", detected_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c67b9-24e8-422e-b156-61c028c27295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
